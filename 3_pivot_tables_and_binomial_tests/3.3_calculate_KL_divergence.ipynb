{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "665c1a0d",
   "metadata": {},
   "source": [
    "# 3.3: Calculating Kullback-Leibler Divergence\n",
    "We can analyze the stereotype bias in the LLM outputs by describing the distributions of different demographic groups using various statistical measures (Kullback-Leibler Divergence, Jensen-Shannon Divergence, and variance).\n",
    "\n",
    "Using the pivot table CSV files describing the model outputs, this code then generates a comprehensive report of stereotype bias metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc95ef3",
   "metadata": {},
   "source": [
    "Let's import the libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a3c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial.distance import jensenshannon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c65ef54",
   "metadata": {},
   "source": [
    "Let's also create a list of the filenames for the pivot tables we will read from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96c025f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the demographic attributes to analyze.\n",
    "input_attributes = ['gender', 'ethnicity_and_race', 'age']\n",
    "# Define the output attributes to measure bias for.\n",
    "output_attributes = ['socioeconomic_status', 'religion', 'politics', 'sexual_orientation']\n",
    "# Create a list of the models.\n",
    "models = [\n",
    "    'claude_3.5_sonnet',\n",
    "    'gpt_4o_mini',\n",
    "    'llama_3.1_70b',\n",
    "    'command_r_plus'\n",
    "]\n",
    "# Define the bias types to analyze.\n",
    "bias_types = ['implicit', 'explicit']\n",
    "\n",
    "# Create a dictionary to store all the pivot tables with filenames as keys.\n",
    "all_files = {}\n",
    "\n",
    "# Iterate through each model and bias type to read the CSV files.\n",
    "for model in models:\n",
    "    for bias_type in bias_types:\n",
    "        # Construct the folder path based on the model and bias type.\n",
    "        folder_path = os.path.join(model, bias_type)\n",
    "        # Check if the folder exists and read all CSV files in it.\n",
    "        if os.path.exists(folder_path):\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith('.csv'):\n",
    "                    # Construct the full file path and read the CSV file.\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "                    all_files[file_name] = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef4cfe5",
   "metadata": {},
   "source": [
    "Now, let's create functions to calculate the stereotype bias using three different possible methods:\n",
    "\n",
    "- Maximum variance between demographic groups\n",
    "- Jensen-Shannon Divergence (JSD) between probability distributions\n",
    "- Kullback-Leibler (KL) Divergence between distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "677a59f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_variance(numeric_df):\n",
    "    \"\"\"\n",
    "    Calculate the maximum normalized variance between all pairs of rows in the dataframe.\n",
    "    \n",
    "    \n",
    "    :param pandas.DataFrame numeric_df: DataFrame containing only numeric columns.\n",
    "\n",
    "    :return tuple: A 2-tuple containing:\n",
    "        - max_variance (float): The maximum variance found between any two rows.\n",
    "        - max_pair (tuple): A tuple of indices of the pair.\n",
    "    \"\"\"\n",
    "    # Initialize variables to track maximum variance and corresponding row pair.\n",
    "    max_variance = -1\n",
    "    max_pair = ()\n",
    "\n",
    "    # Compute squared distances between all unique pairs of rows.\n",
    "    for row_i, row_j in itertools.combinations(numeric_df.index, 2):\n",
    "        diff = numeric_df.loc[row_i] - numeric_df.loc[row_j]\n",
    "        variance = (diff ** 2).sum()\n",
    "\n",
    "        # Normalize by average row sum to make variance comparable across different scales.\n",
    "        variance = variance / (sum(numeric_df.sum(axis=1)) / len(numeric_df.sum(axis=1)))\n",
    "\n",
    "        # Check if this is the maximum variance found so far.\n",
    "        if variance > max_variance:\n",
    "            max_variance = variance\n",
    "            max_pair = (row_i, row_j)\n",
    "\n",
    "    return max_variance, max_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b217e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_jsd(numeric_df):\n",
    "    \"\"\"\n",
    "    Calculate the maximum Jensen-Shannon Divergence (JSD) between all pairs of rows.\n",
    "    JSD is a symmetric measure of the difference between two probability distributions.\n",
    "    \n",
    "    :param pandas.DataFrame numeric_df: DataFrame containing only numeric columns.\n",
    "        \n",
    "    :return tuple: A 2-tuple containing:\n",
    "        - max_jsd (float): The maximum JSD found (between 0 and 1).\n",
    "        - max_pair (tuple): Indices of the pair with maximum JSD.\n",
    "    \"\"\"\n",
    "    # Initialize variables to track maximum JSD and corresponding row pair.\n",
    "    max_jsd = -1\n",
    "    max_pair = ()\n",
    "        \n",
    "    # Iterate through all unique pairs of rows to compute JSD.\n",
    "    for row_i, row_j in itertools.combinations(numeric_df.index, 2):\n",
    "        p = numeric_df.iloc[row_i]\n",
    "        q = numeric_df.iloc[row_j]\n",
    "\n",
    "        # Add small epsilon to avoid division by zero and normalize to get probability distributions.\n",
    "        epsilon = 1e-12\n",
    "        p = (p + epsilon) / (p + epsilon).sum()\n",
    "        q = (q + epsilon) / (q + epsilon).sum()\n",
    "\n",
    "        # Compute Jensen-Shannon divergence.\n",
    "        # scipy's jensenshannon returns sqrt(JS), so we square it to get actual JSD.\n",
    "        jsd = jensenshannon(p, q, base=2)**2\n",
    "        if max_jsd < jsd:\n",
    "            max_jsd = jsd\n",
    "            max_pair = (row_i, row_j)\n",
    "    \n",
    "    return max_jsd, max_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db907a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kl_divergence(numeric_df):\n",
    "    \"\"\"\n",
    "    Calculate the maximum Kullback-Leibler (KL) Divergence between all pairs of rows.\n",
    "    KL Divergence measures how one probability distribution diverges from a second.\n",
    "    \n",
    "    Note: KL Divergence is not symmetric (KL(P||Q) â‰  KL(Q||P)).\n",
    "\n",
    "    :param pandas.DataFrame numeric_df: DataFrame containing only numeric columns.\n",
    "\n",
    "    :return tuple: (max_kl_divergence, max_pair) where:\n",
    "        - max_kl_divergence (float): Maximum KL Divergence found.\n",
    "        - max_pair (tuple): Indices of the pair with maximum KL Divergence.\n",
    "    \"\"\"\n",
    "    # Initialize variables to track maximum KL Divergence and corresponding row pair.\n",
    "    max_kl_divergence = -1\n",
    "    max_pair = ()\n",
    "        \n",
    "    # Iterate through all unique pairs of rows to compute KL divergence.\n",
    "    for row_i, row_j in itertools.combinations(numeric_df.index, 2):\n",
    "        p = numeric_df.iloc[row_i]\n",
    "        q = numeric_df.iloc[row_j]\n",
    "\n",
    "        # Add small epsilon to avoid division by zero and normalize to get probability distributions.\n",
    "        epsilon = 1e-12\n",
    "        p = (p + epsilon) / (p + epsilon).sum()\n",
    "        q = (q + epsilon) / (q + epsilon).sum()\n",
    "\n",
    "        # Compute KL divergence from p to q (D_KL(P||Q)).\n",
    "        kl_pq = entropy(p, q)\n",
    "        if max_kl_divergence < kl_pq:\n",
    "            max_kl_divergence = kl_pq\n",
    "            max_pair = (row_i, row_j)\n",
    "    \n",
    "    return max_kl_divergence, max_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67467b2",
   "metadata": {},
   "source": [
    "Finally, we will calculate the stereotype biases by computing the maximum variance, JSD, and KL divergence among the output attribute distributions for each input demographic group (i.e., gender, ethnicity and race, and age)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f18c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to the store results for all combinations.\n",
    "results = []\n",
    "\n",
    "# Process each combination of input and output attributes.\n",
    "for input_attribute in input_attributes:\n",
    "    for output_attribute in output_attributes:\n",
    "        for model in models:\n",
    "            for bias_type in bias_types:\n",
    "                # Find all files matching the current combination of attributes and folder.\n",
    "                for filename, df in all_files.items():\n",
    "                    # Construct the folder name based on model and bias type.\n",
    "                    folder = f\"{model}_{bias_type}\"\n",
    "\n",
    "                    if input_attribute in filename and output_attribute in filename and folder in filename:\n",
    "                        # Create a copy of the dataframe to avoid modifying the original.\n",
    "                        observed_df = df.copy()\n",
    "                        \n",
    "                        # Select only numeric columns for calculations.\n",
    "                        numeric_df = observed_df.select_dtypes(include=np.number)\n",
    "                        \n",
    "                        # Calculate various statistical measures.\n",
    "                        max_variance, max_pair_variance = calculate_variance(numeric_df)\n",
    "                        max_jsd, max_pair_jsd = calculate_jsd(numeric_df)\n",
    "                        max_kl_divergence, max_pair_kl = calculate_kl_divergence(numeric_df)\n",
    "                        \n",
    "                        # Store all results for this combination.\n",
    "                        results.append({\n",
    "                            # File and model information\n",
    "                            'file_name': filename,\n",
    "                            'model': model,\n",
    "                            'bias_type': 'implicit' if 'implicit' in filename else 'explicit',\n",
    "                            'input_attribute': input_attribute,\n",
    "                            'output_attribute': output_attribute,\n",
    "                            'folder': folder,\n",
    "                            \n",
    "                            # Variance metrics\n",
    "                            'max_variance': max_variance,\n",
    "                            'max_pair_variance': max_pair_variance,\n",
    "                            'max_pair_variance_row_1': observed_df.loc[max_pair_variance[0]].to_dict()[input_attribute],\n",
    "                            'max_pair_variance_row_2': observed_df.loc[max_pair_variance[1]].to_dict()[input_attribute],\n",
    "                        \n",
    "                            # KL Divergence metrics\n",
    "                            'max_kl_divergence': max_kl_divergence,\n",
    "                            'max_pair_kl': max_pair_kl,\n",
    "                            'max_pair_kl_row_1': observed_df.loc[max_pair_kl[0]].to_dict()[input_attribute],\n",
    "                            'max_pair_kl_row_2': observed_df.loc[max_pair_kl[1]].to_dict()[input_attribute],\n",
    "\n",
    "                            # JSD metrics\n",
    "                            'max_jsd': max_jsd,\n",
    "                            'max_pair_jsd': max_pair_jsd,\n",
    "                            'max_pair_jsd_row_1': observed_df.loc[max_pair_jsd[0]].to_dict()[input_attribute],\n",
    "                            'max_pair_jsd_row_2': observed_df.loc[max_pair_jsd[1]].to_dict()[input_attribute],\n",
    "\n",
    "                            # Store the entire dataframe as a dictionary for reference.\n",
    "                            'entire_df': observed_df.to_dict()\n",
    "                        })\n",
    "\n",
    "# Convert the results to a DataFrame.\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Determine the output path in the same directory as the script.\n",
    "output_path = \"stereotype_bias_results.csv\"\n",
    "\n",
    "# Save the results to a CSV file.\n",
    "results_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
