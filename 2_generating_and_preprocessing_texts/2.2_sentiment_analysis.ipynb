{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. Sentiment Analysis of LLM-Generated Texts\n",
    "After generating the texts using our prompts, we will perform sentiment analysis on each LLM-generated text.\n",
    "\n",
    "We will also check the texts for cases where the attributes provided may not appear to be in the actual texts themselves to verify the accuracy of the LLM-generated attribute lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the libraries we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with the texts generated using implicit bias prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load information for accessing the JSON files.\n",
    "implicit_prompt_types_df = pd.read_csv(\"../1_prompt_engineering/implicit_prompt_types.csv\")\n",
    "implicit_jsons = implicit_prompt_types_df[\"json_name\"]\n",
    "\n",
    "# Define the folders where the generated texts are stored. \n",
    "folders = [\"gpt_4o_mini/implicit/\", \"claude_3.5_sonnet/implicit/\", \"command_r_plus/implicit/\", \"llama_3.1_70b/implicit/\"]\n",
    "\n",
    "# Iterate through the folders containing the generated texts.\n",
    "for implicit_texts_folder in folders: \n",
    "    # Get the number of prompt types (same as the number of JSON files).\n",
    "    num_prompt_types = implicit_prompt_types_df.shape[0]\n",
    "    # Keep track of the number of attributes that were not found.\n",
    "    num_attribute_not_found = 0\n",
    "    num_texts_attribute_not_found = 0\n",
    "    num_texts = 0\n",
    "    # Create a list of texts where the attribute that the LLM outputted is not found in the text.\n",
    "    attributes_not_found = []\n",
    "\n",
    "    print(\"Current model:\", implicit_texts_folder)\n",
    "\n",
    "    # Iterate through the JSON files.\n",
    "    for file_num in range(0, num_prompt_types):\n",
    "        json_path = implicit_texts_folder + implicit_jsons.iloc[file_num]\n",
    "        print(\"Processing:\", json_path)\n",
    "\n",
    "        # Open the JSON file as a dictionary.\n",
    "        with open(json_path) as json_file:\n",
    "            generated_texts = json.load(json_file)\n",
    "            print(\"Analyzing sentiment.\")\n",
    "\n",
    "            # Modify the dictionary.\n",
    "            for key in generated_texts.keys():\n",
    "                text = generated_texts[key][\"generated_text\"]\n",
    "                num_texts += 1\n",
    "\n",
    "                # For Llama 3.1, remove the \"Here is a 200-word description of...\" from the text.\n",
    "                if \"Here is\" in text and \"200-word description\" in text:\n",
    "                    # If the keywords are in the text, split it into a list of lines.\n",
    "                    text_lines = text.split(\"\\n\")\n",
    "                    # Remove the first line, recombine the lines into one string, and strip whitespace from the ends.\n",
    "                    updated_text = \"\\n\".join(text_lines[1:]).strip()\n",
    "                    # Reassign the text.\n",
    "                    generated_texts[key][\"generated_text\"] = updated_text\n",
    "\n",
    "                # Check that all of the attributes in the dictionary are found in the text.\n",
    "                all_attributes_found = True\n",
    "                attributes = [\"occupation\", \"socioeconomic_status\", \"religion\", \"politics\", \"sexual_orientation\", \"total_height\"]\n",
    "                \n",
    "                if \"attributes\" in generated_texts[key].keys():\n",
    "                    for attribute in attributes:\n",
    "                        # Get the value of the attribute from the list of attributes given by the LLM.\n",
    "                        value = generated_texts[key][\"attributes\"][attribute]\n",
    "                        # Change the value to lowercase if it's not  height.\n",
    "                        if attribute != \"total_height\":\n",
    "                            value = value.lower()\n",
    "                            generated_texts[key][\"attributes\"][attribute] = value\n",
    "\n",
    "                        # If the attribute is height, convert the integer to string format i.e. [#'#\"].\n",
    "                        if attribute == \"total_height\":\n",
    "                            value =  str(math.floor(value/12)) + \"'\" + str(value % 12) + \"\\\"\"\n",
    "\n",
    "                        # Check if the value is found in the generated text (not case-sensitive).\n",
    "                        found = text.lower().find(value.lower())\n",
    "\n",
    "                        # If it is not found, check for variants, then notify the user by printing a console message and increment the counts.\n",
    "                        if found == -1:\n",
    "                            # Check for synonymous key phrases that are commonly used by LLMs.\n",
    "                            if attribute == \"sexual_orientation\" and value == \"homosexual\":\n",
    "                                value = \"gay\"\n",
    "                                found = text.lower().find(value.lower())\n",
    "                            elif attribute == \"socioeconomic_status\" and value == \"lower-class\":\n",
    "                                value = \"lower-middle-class\"\n",
    "                                found = text.lower().find(value.lower())\n",
    "                                if found == -1:\n",
    "                                    found = text.lower().find(value.lower().replace(\"-\", \" \"))\n",
    "                            elif attribute == \"socioeconomic_status\" and value == \"middle-class\":\n",
    "                                found = text.lower().find(value.lower().replace(\"-\", \" \"))\n",
    "                            elif attribute == \"socioeconomic_status\" and value == \"upper-class\":\n",
    "                                value = \"upper-middle-class\"\n",
    "                                found = text.lower().find(value.lower())\n",
    "                                if found == -1:\n",
    "                                    found = text.lower().find(value.lower().replace(\"-\", \" \"))\n",
    "                            elif attribute == \"occupation\" and value == \"student\":\n",
    "                                value = \"school\"\n",
    "                                found = text.lower().find(value.lower())\n",
    "                            elif attribute == \"religion\":\n",
    "                                # Check for religious synonyms.\n",
    "                                religious_synonyms = {\n",
    "                                    \"christian\": [\"Christianity\", \"Catholic\"],\n",
    "                                    \"muslim\": [\"Islam\"],\n",
    "                                    \"jewish\": [\"Judaism\", \"Jew\"],\n",
    "                                    \"hindu\": [\"Hinduism\"],\n",
    "                                    \"buddhist\": [\"Buddhism\"],\n",
    "                                    \"unaffiliated\": [\"atheist\", \"secular\", \"atheism\", \"secularism\", \"agnostic\", \"agnosticism\"],\n",
    "                                } \n",
    "\n",
    "                                if value in religious_synonyms.keys():\n",
    "                                    corresponding_synonyms = religious_synonyms[value]\n",
    "                                    \n",
    "                                    for synonym in corresponding_synonyms:\n",
    "                                        found = text.lower().find(synonym.lower())\n",
    "                                        if found != -1:\n",
    "                                            break\n",
    "\n",
    "                            # Notify the user and update the list if the value is still not found after checking for variants.\n",
    "                            if found == -1:\n",
    "                                # print(attribute, value, \"was not found in the text for:\", key)\n",
    "                                num_attribute_not_found += 1\n",
    "                                all_attributes_found = False\n",
    "                                attributes_not_found.append((attribute, key))\n",
    "\n",
    "                    # If not all attributes were found, increment the count of texts with attributes not found.\n",
    "                    if not all_attributes_found:\n",
    "                        num_texts_attribute_not_found += 1\n",
    "\n",
    "                    # Analyze the sentiment.\n",
    "                    analysis = TextBlob(text)\n",
    "\n",
    "                    # Add the sentiment to the attributes dictionary.\n",
    "                    generated_texts[key][\"attributes\"][\"polarity\"] = analysis.polarity\n",
    "                    generated_texts[key][\"attributes\"][\"subjectivity\"] = analysis.subjectivity\n",
    "\n",
    "            print(\"Done analyzing sentiment.\")\n",
    "\n",
    "            # Write the dictionary to the output file as JSON data.\n",
    "            with open(json_path, \"w\") as f:\n",
    "                json.dump(generated_texts, f)\n",
    "\n",
    "            print(\"New contents saved.\")\n",
    "\n",
    "    # Print the summary of the analysis.\n",
    "    print(\"Total number of attributes not found in text:\", num_attribute_not_found)\n",
    "    print(\"Total number of texts processed:\", num_texts)\n",
    "    print(\"Total number of texts with attributes not found:\", num_texts_attribute_not_found)\n",
    "    print(\"Percentage of texts with attributes not found:\", num_texts_attribute_not_found / num_texts)\n",
    "    # Notify the user of texts where the attribute was not found.\n",
    "    print(\"Attributes not found in texts:\")\n",
    "    print(attributes_not_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will analyze the texts generated using explicit bias prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load information for accessing the JSON files.\n",
    "explicit_prompt_types_df = pd.read_csv(\"../1_prompt_engineering/explicit_prompt_types.csv\")\n",
    "explicit_jsons = explicit_prompt_types_df[\"json_name\"]\n",
    "\n",
    "folders = [\"gpt_4o_mini/explicit/\", \"claude_3.5_sonnet/explicit/\", \"command_r_plus/explicit/\", \"llama_3.1_70b/explicit/\"]\n",
    "\n",
    "for explicit_texts_folder in folders: \n",
    "    # Get the number of prompt types (same as the number of JSON files).\n",
    "    num_prompt_types = explicit_prompt_types_df.shape[0]\n",
    "    # Keep track of the number of attributes that were not found.\n",
    "    num_attribute_not_found = 0\n",
    "    num_texts_attribute_not_found = 0\n",
    "    num_texts = 0\n",
    "    # Create a list of texts where the attribute that the LLM outputted is found found in the text.\n",
    "    attributes_not_found = []\n",
    "\n",
    "    print(\"Current model:\", explicit_texts_folder)\n",
    "\n",
    "    # Iterate through the JSON files.\n",
    "    for file_num in range(0, num_prompt_types):\n",
    "        json_path = explicit_texts_folder + explicit_jsons.iloc[file_num]\n",
    "        print(\"Processing:\", json_path)\n",
    "\n",
    "        # Open the JSON file as a dictionary.\n",
    "        with open(json_path) as json_file:\n",
    "            generated_texts = json.load(json_file)\n",
    "            print(\"Analyzing sentiment.\")\n",
    "\n",
    "            # Modify the dictionary.\n",
    "            for key in generated_texts.keys():\n",
    "                text = generated_texts[key][\"generated_text\"]\n",
    "                num_texts += 1\n",
    "\n",
    "                all_attributes_found = True\n",
    "\n",
    "                # Check that all of the attributes in the dictionary are found in the text.\n",
    "                attributes = [\"occupation\", \"socioeconomic_status\", \"religion\", \"politics\", \"sexual_orientation\", \"total_height\"]\n",
    "                \n",
    "                if \"attributes\" in generated_texts[key].keys():\n",
    "                    for attribute in attributes:\n",
    "                        # Get the value of the attribute from the list of attributes given by the LLM.\n",
    "                        value = generated_texts[key][\"attributes\"][attribute]\n",
    "                        # Change the value to lowercase if it's not  height.\n",
    "                        if attribute != \"total_height\":\n",
    "                            value = value.lower()\n",
    "                            generated_texts[key][\"attributes\"][attribute] = value\n",
    "\n",
    "                        # If the attribute is height, convert the integer to string format i.e. [#'#\"].\n",
    "                        if attribute == \"total_height\":\n",
    "                            value =  str(math.floor(value/12)) + \"'\" + str(value % 12) + \"\\\"\"\n",
    "\n",
    "                        # Check if the value is found in the generated text (not case-sensitive).\n",
    "                        found = text.lower().find(value.lower())\n",
    "\n",
    "                        # If it is not found, check for variants, then notify the user by printing a console message and increment the counts.\n",
    "                        if found == -1:\n",
    "                            # Check for synonymous key phrases that are commonly used by LLMs.\n",
    "                            if attribute == \"sexual_orientation\" and value == \"homosexual\":\n",
    "                                value = \"gay\"\n",
    "                                found = text.lower().find(value.lower())\n",
    "                            elif attribute == \"socioeconomic_status\" and value == \"lower-class\":\n",
    "                                value = \"lower-middle-class\"\n",
    "                                found = text.lower().find(value.lower())\n",
    "                                if found == -1:\n",
    "                                    found = text.lower().find(value.lower().replace(\"-\", \" \"))\n",
    "                            elif attribute == \"socioeconomic_status\" and value == \"middle-class\":\n",
    "                                found = text.lower().find(value.lower().replace(\"-\", \" \"))\n",
    "                            elif attribute == \"socioeconomic_status\" and value == \"upper-class\":\n",
    "                                value = \"upper-middle-class\"\n",
    "                                found = text.lower().find(value.lower())\n",
    "                                if found == -1:\n",
    "                                    found = text.lower().find(value.lower().replace(\"-\", \" \"))\n",
    "                            elif attribute == \"occupation\" and value == \"student\":\n",
    "                                value = \"school\"\n",
    "                                found = text.lower().find(value.lower())\n",
    "                            elif attribute == \"religion\":\n",
    "                                # Check for religious synonyms.\n",
    "                                religious_synonyms = {\n",
    "                                    \"christian\": [\"Christianity\", \"Catholic\"],\n",
    "                                    \"muslim\": [\"Islam\"],\n",
    "                                    \"jewish\": [\"Judaism\", \"Jew\"],\n",
    "                                    \"hindu\": [\"Hinduism\"],\n",
    "                                    \"buddhist\": [\"Buddhism\"],\n",
    "                                    \"unaffiliated\": [\"atheist\", \"secular\", \"atheism\", \"secularism\", \"agnostic\", \"agnosticism\"],\n",
    "                                } \n",
    "\n",
    "                                if value in religious_synonyms.keys():\n",
    "                                    corresponding_synonyms = religious_synonyms[value]\n",
    "                                    \n",
    "                                    for synonym in corresponding_synonyms:\n",
    "                                        found = text.lower().find(synonym.lower())\n",
    "                                        if found != -1:\n",
    "                                            break\n",
    "\n",
    "                            # Notify the user and update the list if the value is still not found after checking for variants.\n",
    "                            if found == -1:\n",
    "                                # print(attribute, value, \"was not found in the text for:\", key)\n",
    "                                num_attribute_not_found += 1\n",
    "                                all_attributes_found = False\n",
    "                                attributes_not_found.append((attribute, key))\n",
    "                                \n",
    "                    # If not all attributes were found, increment the count of texts with attributes not found.\n",
    "                    if not all_attributes_found:\n",
    "                        num_texts_attribute_not_found += 1\n",
    "\n",
    "                    # Analyze the sentiment.\n",
    "                    analysis = TextBlob(text)\n",
    "\n",
    "                    # Add the sentiment to the attributes dictionary.\n",
    "                    generated_texts[key][\"attributes\"][\"polarity\"] = analysis.polarity\n",
    "                    generated_texts[key][\"attributes\"][\"subjectivity\"] = analysis.subjectivity\n",
    "\n",
    "            print(\"Done analzying sentiment.\")\n",
    "\n",
    "            # Write the dictionary to the output file as JSON data.\n",
    "            with open(json_path, \"w\") as f:\n",
    "                json.dump(generated_texts, f)\n",
    "\n",
    "            print(\"New contents saved.\")\n",
    "\n",
    "    # Print the summary of the analysis.\n",
    "    print(\"Total number of attributes not found in text:\", num_attribute_not_found)\n",
    "    print(\"Total number of texts processed:\", num_texts)\n",
    "    print(\"Total number of texts with attributes not found:\", num_texts_attribute_not_found)\n",
    "    print(\"Percentage of texts with attributes not found:\", num_texts_attribute_not_found / num_texts)\n",
    "    # Notify the user of texts where the attribute was not found.\n",
    "    print(\"Attributes not found in texts:\")\n",
    "    print(attributes_not_found)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
